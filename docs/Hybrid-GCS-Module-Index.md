# Hybrid-GCS Module Index & Quick Reference

**Quick Navigation for Implementation**

---

## üìë Core Module Reference

### **1. Configuration Space** (`hybrid_gcs/core/config_space.py`)

```python
class ConfigSpace:
    """Defines state/action bounds and properties"""
    
    # Key methods:
    - is_valid(q) ‚Üí bool          # Check if config is valid
    - project(q) ‚Üí np.ndarray     # Project to valid space
    - random_sample() ‚Üí np.ndarray # Sample random config
    - distance(q1, q2) ‚Üí float    # Compute distance
    - interpolate(q1, q2, t) ‚Üí np.ndarray  # Linear interpolation
```

**Used by:** IRIS, MICP, trajectories  
**Test file:** `tests/test_core/test_config_space.py`  
**Example:** Every module needs ConfigSpace instance

---

### **2. Trajectory Representation** (`hybrid_gcs/core/trajectory.py`)

```python
class Trajectory:
    """Smooth trajectory through waypoints via splines"""
    
    # Key methods:
    - at_time(t) ‚Üí np.ndarray              # Get config at time t
    - derivatives_at_time(t, n) ‚Üí np.ndarray  # Get n-th derivative
    - length() ‚Üí float                     # Total trajectory length
    - resample(n_waypoints) ‚Üí Trajectory   # Resample to n points
    - smooth(factor) ‚Üí Trajectory          # Apply smoothing

class BezierTrajectory:
    """Trajectory parameterized by Bezier control points"""
    
    # Key methods:
    - eval(t) ‚Üí np.ndarray                 # Evaluate at parameter t
    - derivative(t) ‚Üí np.ndarray           # Get first derivative
    - to_trajectory(n_samples) ‚Üí Trajectory  # Convert to waypoint form
```

**Used by:** MICP solver output, RL planning, visualization  
**Test file:** `tests/test_core/test_trajectory.py`

---

### **3. IRIS Decomposition** (`hybrid_gcs/core/iris_decomposer.py`)

```python
class IRISDecomposer:
    """Decomposes space into convex regions via IRIS algorithm"""
    
    # Key methods:
    - decompose(obstacles, seeds, max_regions) ‚Üí GCSGraph
    - _grow_ellipsoid(center, obstacles) ‚Üí Ellipsoid
    - _build_graph(regions) ‚Üí GCSGraph

class Ellipsoid:
    """Convex set represented as ellipsoid"""
    
    # Key methods:
    - contains(point) ‚Üí bool
    - volume() ‚Üí float
```

**Used by:** GCS graph construction  
**Test file:** `tests/test_core/test_iris_decomposer.py`  
**Reference:** Hybrid-GCS-Theory.md Section 1.3

---

### **4. MICP Solver** (`hybrid_gcs/core/micp_solver.py`)

```python
class MICPSolver:
    """Solves shortest path in GCS via Mixed-Integer Convex Programming"""
    
    # Key methods:
    - solve(start, goal, **kwargs) ‚Üí Optional[Trajectory]
    - _build_problem(start, goal) ‚Üí Dict
    - _solve_mosek(problem) ‚Üí Optional[Dict]
    - _solve_gurobi(problem) ‚Üí Optional[Dict]
    - _extract_trajectory(solution) ‚Üí Trajectory
```

**Used by:** GCS planner, hybrid action selection  
**Test file:** `tests/test_core/test_micp_solver.py`  
**Solvers:** Mosek, Gurobi, SCS (free alternative)  
**Typical runtime:** 1-10 seconds for 20-50 regions

---

### **5. Collision Checker** (`hybrid_gcs/core/collision_checker.py`)

```python
class CollisionChecker:
    """Fast collision detection for workspace"""
    
    # Key methods:
    - in_collision(config) ‚Üí bool
    - trajectory_collision(trajectory) ‚Üí bool
    - distance_to_obstacle(config) ‚Üí float
    - check_path_collision(q1, q2) ‚Üí bool
```

**Used by:** IRIS, safety filter  
**Typical implementation:** FCL (Fast Collision Library)

---

### **6. Kinematics** (`hybrid_gcs/core/kinematics.py`)

```python
class RobotKinematics:
    """Forward and inverse kinematics for robot arm"""
    
    # Key methods:
    - forward(joint_config) ‚Üí (position, orientation)
    - inverse(pose, q_init) ‚Üí Optional[joint_config]
    - jacobian(joint_config) ‚Üí np.ndarray
    - check_joint_limits(joint_config) ‚Üí bool
```

**Used by:** YCB grasping, any arm control  
**Typical implementation:** PyKDL or Drake

---

## üß† Training Module Reference

### **7. Policy Network** (`hybrid_gcs/training/policy_network.py`)

```python
class PolicyNetwork(torch.nn.Module):
    """Actor-Critic network for continuous control"""
    
    # Key methods:
    - forward(state) ‚Üí (dist, value)
    - get_action(state) ‚Üí (action, log_prob)
    - get_value(state) ‚Üí value

class CNNEncoder(torch.nn.Module):
    """CNN for encoding RGB-D images"""
    
    # Key methods:
    - forward(images) ‚Üí features
```

**Inputs:** State [batch, state_dim]  
**Outputs:** Action distribution + value estimate  
**Architecture:** Shared trunk + separate actor/critic heads  
**Test file:** `tests/test_training/test_policy_network.py`

---

### **8. PPO Trainer** (`hybrid_gcs/training/ppo_trainer.py`)

```python
class PPOTrainer:
    """Proximal Policy Optimization training loop"""
    
    # Key methods:
    - compute_gae(rewards, values, dones) ‚Üí (advantages, returns)
    - update_policy(trajectories) ‚Üí Dict[loss metrics]
    
    # Key hyperparameters:
    - gamma: 0.99 (discount factor)
    - gae_lambda: 0.95 (GAE parameter)
    - clip_ratio: 0.2 (PPO clipping Œµ)
    - entropy_coeff: 0.01 (exploration)
```

**Training pipeline:**
1. Collect trajectories with current policy
2. Compute GAE advantages
3. Multiple epochs of gradient updates with clipping
4. Value network regression

**Test file:** `tests/test_training/test_ppo_trainer.py`

---

### **9. Reward Shaper** (`hybrid_gcs/training/reward_shaper.py`)

```python
class RewardShaper:
    """Shapes rewards for better learning"""
    
    # Key methods:
    - compute_task_reward(obs, action, next_obs) ‚Üí float
    - compute_gcs_bonus(gcs_action, action) ‚Üí float
    - compute_exploration_bonus(state) ‚Üí float
```

**Components:**
- Task-specific reward (progress, goal)
- GCS alignment bonus (encourage following planner)
- Exploration bonus (encourage new states)
- Smoothness penalty

---

### **10. Curriculum Scheduler** (`hybrid_gcs/training/curriculum_scheduler.py`)

```python
class CurriculumScheduler:
    """Progressive difficulty scheduling"""
    
    # Key methods:
    - get_difficulty_level(iteration) ‚Üí float
    - sample_task_config() ‚Üí Dict
    - should_advance() ‚Üí bool
```

**Strategies:**
- Increase number of objects over time
- Increase environment randomization
- Gradually reduce GCS reliance

---

### **11. Experience Buffer** (`hybrid_gcs/training/experience_buffer.py`)

```python
class ExperienceBuffer:
    """Stores and samples trajectories for training"""
    
    # Key methods:
    - append(trajectory)
    - sample_batch(batch_size) ‚Üí Dict
    - get_minibatches(batch_size) ‚Üí Iterator
```

**Storage:** [states, actions, rewards, dones, values, log_probs]

---

## üîÑ Integration Module Reference

### **12. Feature Extractor** (`hybrid_gcs/integration/feature_extractor.py`)

```python
class FeatureExtractor:
    """Extracts features for GCS and RL from observations"""
    
    # Key methods:
    - extract(observation) ‚Üí Dict[gcs_features, rl_features]
    - _get_vision_features(observation) ‚Üí np.ndarray
    - _pad_or_truncate(features, target_dim) ‚Üí np.ndarray
```

**Output:**
- `gcs_features`: Low-dim (50-100) for planner
- `rl_features`: High-dim (512+) for policy

---

### **13. Hybrid Policy** (`hybrid_gcs/integration/hybrid_policy.py`)

```python
class HybridPolicy:
    """Combines GCS planner and RL policy"""
    
    # Key methods:
    - get_action(state, gcs_features, replan) ‚Üí action
    - _get_gcs_action(features, replan) ‚Üí action
    - _get_rl_action(state) ‚Üí action
    - _blend_weighted(gcs_action, rl_action) ‚Üí action
    - _blend_hierarchical(gcs_action, rl_action) ‚Üí action
```

**Blending strategies:**
1. **Weighted:** `a = (1-w)*a_gcs + w*a_rl` (w increases over training)
2. **Hierarchical:** Use GCS if feasible, else RL
3. **Conflict resolution:** Priority network decides

---

### **14. Action Selector** (`hybrid_gcs/integration/action_selector.py`)

```python
class ActionSelector:
    """Selects between GCS and RL actions"""
    
    # Key methods:
    - select_action(state, gcs_action, rl_action) ‚Üí action
    - should_use_gcs(state) ‚Üí bool
    - compute_confidence(action) ‚Üí float
```

---

### **15. Safety Filter** (`hybrid_gcs/integration/safety_filter.py`)

```python
class SafetyFilter:
    """Enforces real-time safety constraints"""
    
    # Key methods:
    - filter_action(action, state) ‚Üí safe_action
    - project_to_safe_set(action) ‚Üí safe_action
    - check_collision(action) ‚Üí bool
    - enforce_joint_limits(action) ‚Üí action
    - enforce_torque_limits(action) ‚Üí action
```

**Implementation:** Fast QP solver (100Hz capable)

---

## üéÆ Environment Module Reference

### **16. Base Environment** (`hybrid_gcs/environments/base_env.py`)

```python
class HybridGCSEnv(gym.Env):
    """Abstract base for all Hybrid-GCS environments"""
    
    # Required methods:
    - reset() ‚Üí obs
    - step(action) ‚Üí (obs, reward, done, info)
    - get_gcs_features() ‚Üí np.ndarray
    - get_rl_features() ‚Üí np.ndarray
```

---

### **17. YCB Grasping** (`hybrid_gcs/environments/ycb_grasping_env.py`)

```python
class YCBGraspingEnv(HybridGCSEnv):
    """Single/dual-arm grasping with YCB objects"""
    
    # Config:
    - robot_type: 'ur5' | 'kuka' | 'dual_arm'
    - gripper_type: 'parallel' | 'anthropomorphic'
    - num_objects: 5-20
    - difficulty: 'easy' | 'medium' | 'hard'
    
    # Action: [arm_joints...] + [gripper]
    # Reward: proximity + contact + lift bonus
```

**Metrics:** Success rate, grasp quality, time-to-grasp

---

### **18. Drone Navigation** (`hybrid_gcs/environments/drone_navigation_env.py`)

```python
class DroneNavigationEnv(HybridGCSEnv):
    """Single/multi-agent drone navigation"""
    
    # Config:
    - num_drones: 1-4
    - environment_type: 'cluttered' | 'forest' | 'urban'
    - num_obstacles: 10-50
    - multi_agent: True | False
    
    # Action: [vx, vy, vz, œâ_z] per drone
    # Reward: goal progress + collision avoidance
```

**Metrics:** Success rate, path length, safety

---

### **19. Manipulation** (`hybrid_gcs/environments/manipulation_env.py`)

```python
class ManipulationEnv(HybridGCSEnv):
    """Complex multi-step manipulation tasks"""
    
    # Config:
    - task: 'pick_place' | 'assembly' | 'stacking'
    - complexity: 'simple' | 'complex'
    
    # Action: End-effector velocity commands
    # Reward: Task progress + efficiency
```

**Metrics:** Success rate, task completion time, smoothness

---

## üìä Evaluation Module Reference

### **20. Metrics** (`hybrid_gcs/evaluation/metrics.py`)

```python
class Metrics:
    """Computes performance metrics"""
    
    # Methods:
    - success_rate() ‚Üí float
    - trajectory_length() ‚Üí float
    - execution_time() ‚Üí float
    - smoothness() ‚Üí float
    - collision_count() ‚Üí int
    - coverage() ‚Üí float
```

---

### **21. Analyzer** (`hybrid_gcs/evaluation/analyzer.py`)

```python
class TrajectoryAnalyzer:
    """Analyzes trajectory quality"""
    
    # Methods:
    - compute_curvature(trajectory) ‚Üí np.ndarray
    - compute_velocity_profile(trajectory) ‚Üí np.ndarray
    - detect_anomalies(trajectory) ‚Üí List
    - compare_trajectories(traj1, traj2) ‚Üí Dict
```

---

## üìÅ File Dependencies Map

```
config_space.py
    ‚Üì (used by)
trajectory.py, iris_decomposer.py, kinematics.py

iris_decomposer.py
    ‚Üì (uses)
collision_checker.py, config_space.py
    ‚Üì (creates)
GCS graph ‚Üí micp_solver.py

micp_solver.py
    ‚Üì (outputs)
trajectory.py objects

feature_extractor.py
    ‚Üì (used by)
hybrid_policy.py, rl_policy.py

policy_network.py
    ‚Üì (used by)
ppo_trainer.py, hybrid_policy.py

ppo_trainer.py
    ‚Üì (updates)
policy_network.py using experience_buffer.py

hybrid_policy.py
    ‚Üì (uses)
micp_solver.py, policy_network.py, safety_filter.py

safety_filter.py
    ‚Üì (uses)
collision_checker.py, kinematics.py

environments
    ‚Üì (use)
All above modules
```

---

## üöÄ Implementation Order

**For minimal viable product (MVP):**

1. ‚úÖ ConfigSpace
2. ‚úÖ Trajectory
3. ‚úÖ IRIS Decomposer
4. ‚úÖ MICP Solver
5. ‚úÖ PolicyNetwork + PPO Trainer
6. ‚úÖ Feature Extractor
7. ‚úÖ Hybrid Policy
8. ‚úÖ YCB Grasping Environment
9. ‚úÖ Metrics
10. ‚úÖ CLI tools

**For full system:**

Add: Safety Filter, Curriculum, Conflict Resolver, Multi-environment support, Hardware interface

---

## üîó Cross-Module Interfaces

### **GCS ‚Üí Trajectory**
```python
trajectory = micp_solver.solve(start, goal)
waypoint = trajectory.at_time(t)
deriv = trajectory.derivatives_at_time(t, n=1)
```

### **Feature Extractor ‚Üí Hybrid Policy**
```python
features_dict = feature_extractor.extract(obs)
action = hybrid_policy.get_action(
    state=features_dict['rl'],
    gcs_features=features_dict['gcs']
)
```

### **PPO Trainer ‚Üí PolicyNetwork**
```python
dist, value = policy_network(state_batch)
loss = ppo_trainer.compute_loss(dist, value, advantages)
```

### **Safety Filter ‚Üí Collision Checker**
```python
safe_action = safety_filter.filter_action(action, state)
# Internally:
is_safe = collision_checker.in_collision(next_state)
```

---

## ‚ö° Performance Targets

| Module | Operation | Target Time |
|--------|-----------|------------|
| IRIS | Decompose 2D space | <1 second |
| MICP | Solve 20 regions | 1-5 seconds |
| Feature Extract | Per observation | <1 ms |
| Policy Forward | 100 samples | <10 ms |
| PPO Update | 1 epoch | <100 ms |
| Safety Filter | Per action | <2 ms |
| **Total (realtime)** | Control cycle | <10 ms |

---

## üìû Module Troubleshooting

### **IRIS decomposition slow?**
‚Üí Reduce max_iterations, use fewer seed points, disable visualization

### **MICP solver infeasible?**
‚Üí Add more regions, check collision detector, increase solver time limit

### **RL training not improving?**
‚Üí Check reward shaping, increase curriculum difficulty, tune learning rate

### **High latency in closed-loop?**
‚Üí Use hierarchical policy (GCS only when needed), reduce feature dimension, batch inference

### **Safety filter rejecting too many actions?**
‚Üí Loosen constraints, use control barrier functions instead of hard constraints

---

**This quick reference lets you jump between modules efficiently during implementation!**

